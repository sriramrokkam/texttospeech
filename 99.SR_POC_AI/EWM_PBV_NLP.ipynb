{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proof of Concept: Voice Assistant with Cognitive AI to help complete Warehouse Operations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Business Requirement:  \n",
    "1.  Get the input from User over microphone, to Text and interface with SAP EWM as input.\n",
    "2.  Voice request for  inputs and promots for Error for user corrections.\n",
    "3.  Train the AI model with L1/L2 Support, assisting the opertors \n",
    "    on realtime exception handling and workarounds."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Developer           :   ROKKAMS(s.rokkam@sap.com).\n",
    "GitReposit         :   https://github.com/sriramrokkam/texttospeech"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backend Technologies:  \n",
    "   1. Azure -Cognitive AI      for NLP Services\n",
    "   2. SAP S4 Embedded EWM 9.3   for Warehouse Operations.\n",
    "   3. SAP ABAP                  for Server Side Validation.\n",
    "    4. Python 3.3               for Client Side Validations\n",
    "#Integration Technologies:\n",
    "   1.Azure Event Hub\n",
    "   2.SAP ABAP Webhooks\n",
    "   3.Restful API's. \n",
    "                    \n",
    "#Frontend Technologies:\n",
    "   1. SAP AppGyver\n",
    "   2. Django / CSS / JS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import namespaces\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "import os\n",
    "import azure.cognitiveservices.speech as speech_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Configuration Settings\n",
    "load_dotenv()\n",
    "GV_COGKEY = os.getenv('COG_SERVICE_KEY')\n",
    "GV_COGREG = os.getenv('COG_SERVICE_REGION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "S2T"
    ]
   },
   "outputs": [],
   "source": [
    "#New Class for initiating Speech_Config\n",
    "class get_speech:\n",
    "    def __init__(self, GV_COGKEY, GV_COGREG):\n",
    "    # Configure speech service\n",
    "        global speech_config\n",
    "    speech_config = speech_sdk.SpeechConfig(GV_COGKEY, GV_COGREG)\n",
    "    print('Ready to use speech service in:', speech_config.region)\n",
    "\n",
    "obj_getsp = get_speech(GV_COGKEY, GV_COGREG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transcribe\n",
    "class S2T:\n",
    "    def TranscribeCommand(self):\n",
    "        command = ''\n",
    "    # automatic language detection.\n",
    "    auto_detect_source_language_config = speech_sdk.languageconfig.AutoDetectSourceLanguageConfig()\n",
    "    # Configure speech recognition\n",
    "    audio_config = speech_sdk.AudioConfig(use_default_microphone=True)\n",
    "    speech_recognizer = speech_sdk.SpeechRecognizer(obj_getsp.speech_config, audio_config)\n",
    "    print('Speak now...')\n",
    "\n",
    "    # Process speech input\n",
    "    speech = speech_recognizer.recognize_once_async().get()\n",
    "    if speech.reason == speech_sdk.ResultReason.RecognizedSpeech:\n",
    "        command = speech.text\n",
    "        print(command)\n",
    "    else:\n",
    "        print(speech.reason)\n",
    "    if speech.reason == speech_sdk.ResultReason.Canceled:\n",
    "        cancellation = speech.cancellation_details\n",
    "        print(cancellation.reason)\n",
    "        print(cancellation.error_details)     \n",
    "\n",
    "obj_s2t = S2T()\n",
    "obj_s2t.TranscribeCommand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Text to Speech Class.\n",
    "class T2S:\n",
    "    def detect_language(self,text):\n",
    "         # create the auto detection language configuration without specific languages\n",
    "        source_language = speech_sdk.languageconfig.AutoDetectSourceLanguageConfig()\n",
    "        print (source_language)\n",
    "\n",
    "    # Creates a speech synthesizer using the default speaker as audio output.\n",
    "        speech_synthesizer = speech_sdk.SpeechSynthesizer( speech_config=obj_s2t.speech_config, auto_detect_source_language_config=source_language)\n",
    "\n",
    "        result = speech_synthesizer.speak_text_async(obj_s2t.command).get()\n",
    "    # Check result\n",
    "        if result.reason == speech_sdk.ResultReason.SynthesizingAudioCompleted:\n",
    "            print(\"Speech synthesized to speaker for text [{}]\".format(text))\n",
    "        stream = obj_s2t.speech_sdk.AudioDataStream(result)\n",
    "        stream.save_to_wav_file(r\"C:\\05.TexttoSpeech\\output.wav\")\n",
    "\n",
    "\n",
    "'''read_text = input(\"Enter Text to Read :\")'''\n",
    "read_text = obj_s2t.command\n",
    "obj_t2s = T2S()\n",
    "obj_t2s.detect_language(read_text)     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
